{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitle(url):\n",
    "    myUrl = url\n",
    "    uClient = uReq(myUrl)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html,'html.parser')\n",
    "    title = str(page_soup.title)[7:-8]\n",
    "    print(title)\n",
    "\n",
    "def getHyperLink(url):\n",
    "    linkSet = set()\n",
    "    myUrl = url\n",
    "    uClient = uReq(myUrl)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()  \n",
    "    page_soup = soup(page_html,'html.parser')\n",
    "    \n",
    "    all_links= page_soup.findAll('a')\n",
    "    \n",
    "    for link in all_links:\n",
    "        \n",
    "        link_Str = str(link)\n",
    "\n",
    "        if('a href' in link_Str):\n",
    "            \n",
    "            link= (link_Str.split('<a href=\"')[1])\n",
    "            link=(link.split('\"')[0])\n",
    "\n",
    "            if(('javascript:' not in link )& ('@' not in link)):\n",
    "                link = fixUrl(link)\n",
    "                print(link)\n",
    "                linkSet.add(link)\n",
    "    return linkSet\n",
    "\n",
    "def fixUrl(url):\n",
    "    if(url[0:2]=='//'):\n",
    "        url =  \"https:\" + url \n",
    "    return url\n",
    "\n",
    "def getImage(url):\n",
    "    myUrl = url\n",
    "    uClient = uReq(myUrl)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()  \n",
    "    page_soup = soup(page_html,'html.parser')\n",
    "\n",
    "    for img in page_soup.findAll('img'):\n",
    "        response = requests.get(fixUrl(img.get(\"src\")))\n",
    "        imageBuffer = Image.open(BytesIO(response.content))\n",
    "        print(f'name: {img.get(\"title\")} , URL: {fixUrl(img.get(\"src\"))} , width: {imageBuffer.size[0]} , height {imageBuffer.size[1]}, alt: {img.get(\"alt\")}')\n",
    "\n",
    "\n",
    "def getMeta(url):\n",
    "    myUrl = url\n",
    "    uClient = uReq(myUrl)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()  \n",
    "    page_soup = soup(page_html,'html.parser')\n",
    "    for meta in page_soup.findAll('meta'):\n",
    "        if('description' in str(meta).lower()):\n",
    "            print(f\"description: {meta.get('content')}\")\n",
    "        if('keyword' in str(meta).lower()):\n",
    "            print(f\"keyword: {meta.get('content')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     #getTitle(\"https://www.blizzard.com/en-us/\")\n",
    "     getHyperLink(\"https://www.blizzard.com/en-us/\")\n",
    "     #getImage(\"https://www.newegg.com/global/nz\")\n",
    "     #getMeta(\"https://www.newegg.com/global/nz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
